#
# Configuration file for running importance sampling.
#

# General settings
checkpoint_file_name: "model__best.pt"
random_seed: 42
kwargs_for_model: {}

# Define target spectrum
target_spectrum:
  file_path: "..."
  index: 0

# Prior settings
prior:
  dataset: vasist_2023

# Likelihood settings
likelihood:
  sigma: 0.1257

# Simulator settings
simulator:
  dataset: vasist_2023
  kwargs:
    R: 1000
    time_limit: 15

# Stage 1: Draw samples from the proposal distribution
draw_proposal_samples:
  chunk_size: 1024
  n_samples: 2048
  htcondor:
    bid: 50
    num_cpus: 4
    num_gpus: 1
    memory_cpus: 50_000
    memory_gpus: 50_000
    log_file_name: "draw_proposal_samples.$(Process)"
    queue: 4  # = number of parallel jobs

# Stage 2: Merge the samples from the proposal distribution
merge_proposal_samples:
  htcondor:
    bid: 50
    num_cpus: 2
    memory_cpus: 50_000
    log_file_name: "merge_proposal_samples.$(Process)"

# Stage 3: Simulate spectra for the proposal samples
simulate_spectra:
  htcondor:
    bid: 50
    num_cpus: 32
    memory_cpus: 50_000
    log_file_name: "simulate_spectra.$(Process)"
    queue: 32  # = number of parallel jobs

# Stage 4: Merge the results from all jobs and compute the weights
merge_simulation_results:
  htcondor:
    bid: 50
    num_cpus: 2
    memory_cpus: 50_000
    log_file_name: "merge_simulation_results.$(Process)"

# -----------------------------------------------------------------------------
# DATASET AND THETA SCALER
# -----------------------------------------------------------------------------

dataset:
  file_path: "$FM4AR_DATASETS_DIR/vasist-2023/train/selected.hdf"
  train_fraction: 0.95
  n_samples: 17

theta_scaler:
  method: "MinMaxScaler"
  kwargs:
    dataset: "vasist-2023"

# -----------------------------------------------------------------------------
# MODEL ARCHITECTURE
# -----------------------------------------------------------------------------

model:

  # General settings
  model_type: "fmpe"
  t_theta_with_glu: True
  context_with_glu: False
  sigma_min: 0.0001
  time_prior_exponent: 2.0

  # Embedding network for context
  context_embedding_net:
    - block_type: "Concatenate"
      kwargs:
        keys: ["wlen", "flux"]
    - block_type: "DenseResidualNet"
      kwargs:
        hidden_dims: [256, ]
        activation: "ELU"
        output_dim: 4096
        dropout: 0.0
        batch_norm: False

  # Embedding network for (t, theta)
  t_theta_embedding_net:
    - block_type: "PositionalEncoding"
      kwargs:
        n_freqs: 5
        encode_theta: False
    - block_type: "DenseResidualNet"
      kwargs:
        hidden_dims: [64, 32]
        activation: "GELU"
        output_dim: 32
        dropout: 0.0
        batch_norm: False

  # Vector field network
  vectorfield_net:
    network_type: "DenseResidualNet"
    kwargs:
      hidden_dims: [64, 32, 16]
      activation: "GELU"
      dropout: 0.3
      batch_norm: True

# -----------------------------------------------------------------------------
# TRAINING
# -----------------------------------------------------------------------------

training:

  stage_0:
    batch_size: 1024
    data_transforms:
      - method: "add_noise"
        kwargs:
          random_seed: 42
          complexity: 0
          transform: "lambda wlen, error: 0.1257 * error"
    early_stopping: 100
    epochs: 5
    float32_matmul_precision: "high"
    gradient_clipping:
      max_norm: 1.0
    logprob_epochs: -1
    optimizer:
      type: "AdamW"
      kwargs:
        lr: 5.0e-4
    scheduler:
      type: "ReduceLROnPlateau"
      kwargs:
        factor: 0.5
        patience: 10
        min_lr: 5.0e-8
    use_amp: False  # only works on GPU

# -----------------------------------------------------------------------------
# LOCAL SETTINGS
# -----------------------------------------------------------------------------

local:

  # General settings: device, runtime limits, ...
  # Note: If training locally on a Mac, set num_workers to 0!
  device: "cpu"
  num_workers: 0
  runtime_limits:
    max_time_per_run: 36_000

  # Settings for HTCondor
  condor:
    bid: 25
    num_cpus: 8
    memory_cpus: 200_000
    num_gpus: 1
    memory_gpus: 85_000

  # Settings for Weights & Biases, remove if not used
  # wandb:
  #   project: "fm4ar"

# -----------------------------------------------------------------------------
# DATASET AND SCALERS
# -----------------------------------------------------------------------------

dataset:
  name: "inaf"
  data_dir: "$FM4AR_DATASETS_DIR/SBI_INAF"
  verbose: true
  limit: null
  random_seed: 42

theta_scaler:
  method: "MeanStdScaler"
  kwargs:
    dataset: "inaf"
    file_path: "$FM4AR_DATASETS_DIR/SBI_INAF/norm_params.pkl"


# -----------------------------------------------------------------------------
# MODEL ARCHITECTURE
# -----------------------------------------------------------------------------

model:

  # General settings
  model_type: "npe"
  random_seed: 42

  # Embedding network for context
  context_embedding_net:
    - block_type: "SoftClipFlux"
      kwargs:
        bound: 100.0
    - block_type: "Normalize"
      kwargs:
        keys: ["flux", "error_bars", "wlen"]
    - block_type: "WavelengthPositionalEncoding"
      kwargs:
        keys: ["flux", "error_bars", "wlen"]
        fusion_type: "add"
    - block_type: "Unsqueeze"
      kwargs:
        keys: ["flux", "error_bars"]
        dim: 1
    - block_type: "Concatenate"
      kwargs:
        keys: ["flux", "error_bars"]
    # - block_type: "WavelengthPositionalEncoding"
    #   kwargs:
    #     keys: ["flux", "error_bars", "wlen"]
    # TODO: insert TransformerEncoder block here
    - block_type: "TransformerEncoder"
      kwargs:
        seq_length: 102400
        in_channels: 2
        patch_size: 2048
        attn_layers_dim: 512
        attn_layers_depth: 2  
        attn_layers_heads: 8
        embedding_dropout_rate: 0.1
        use_flash_attention: false
    - block_type: "DenseResidualNet"  
      kwargs:
        hidden_dims: [512, 512]
        activation: "GELU"
        output_dim: 512
        dropout: 0.1
        use_layer_norm: true

  # Discrete normalizing flow (wrapped in a compatibility layer)
  # Note: normflows uses slightly different kwargs (see unit tests for demo)
  flow_wrapper:
    flow_library: "glasflow"
    kwargs:
      num_flow_steps: 16
      base_transform_type: "rq-coupling"
      base_transform_kwargs:
        hidden_dim: 512
        num_transform_blocks: 4
        activation: "GELU"
        dropout_probability: 0.1
        use_batch_norm: false
        num_bins: 16
        tail_bound: 10.0


# -----------------------------------------------------------------------------
# TRAINING
# -----------------------------------------------------------------------------

training:

  stage_0:
    backup_interval: 10
    batch_size: 64
    n_workers: 16
    data_transforms:
      - type: "AddCustomNoise"
        kwargs:
          type: "DefaultNoiseGenerator"
          kwargs:
            sigma_min: 0.05
            sigma_max: 0.50
            random_seed: 42
    early_stopping:
      stage_patience: 20
    epochs: 20
    float32_matmul_precision: "high"
    gradient_clipping:
      enabled: true
      max_norm: 1.0
    logprob_evaluation:
      interval: null
      n_samples: 2048
    optimizer:
      type: "AdamW"
      kwargs:
        lr: 5.0e-5
    scheduler:
      type: "CosineAnnealingLR"
      kwargs:
        T_max: 20
    use_amp: false

# -----------------------------------------------------------------------------
# LOCAL SETTINGS
# -----------------------------------------------------------------------------

local:

  # Device ("cpu" or "cuda"; or "auto")
  device: "cuda"

  
  # Settings for Weights & Biases, remove if not used
  wandb:
    project: "fm4ar"
    group: "inaf"
    name: "npe__wavelength-positional-encoding"
